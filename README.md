# gscraper
This is a scraper made for the website gutenberg.org in python. It also removes most of the parts which where generated by the uploading site (e.g. leagal text) 
during the scraping proccess. This obviously slows down the speed by quite a bit. If you do not want this to happen you can just wirte the respective command when executing.
Due to it's unfinished state it will only get about 60-70% of the books and with trimming might take around 10 hours, depending on your available bandwidth and pc specs.

# Features
- Scraps the Books and saves them as .txt files
- during the proccess the script already removes gutenbergs unwanted addons (header & legal text)
- Can iterate through all available books by setting the var "end" to the highest book number (Default setting is 75,000)

# Known Issues
- Doesn't recognize some books due to "missing pattern"
- HTTP Error 406 frequently keeps preventing the access to particular books
- Notice: Some books can't be accessed/scraped in some countries due to copyright issues

# Troubleshooting
- If the script happens to be constantly blocked for accessing the site by the protections try the following:
    Change User-Agents by adding more and / or removing the old ones
    Change the timeout var to 5

# Upcoming Features
- Make automatic styling of the .txt files optional
- QoL changes

